{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 297,
     "status": "ok",
     "timestamp": 1641196298060,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "LHERlet9TZDN"
   },
   "outputs": [],
   "source": [
    "# *** version History \n",
    "# ------------------- Done -------------------------\n",
    "# ver1. : dafault -> metric = \"F1\"\n",
    "# ver2. : Changing training metric  --->  from 'F1' to \"AUC\"\n",
    "#   => Max_iter=3000 까지 수렴하지 않고 계속 학습되는 현상 발생 \n",
    "#      -> Parameter Optimisation for searching Global minimum issue \n",
    "#   => 성능 개선 \n",
    "#      -> 확실히, 'AUC' 최대 기준의 model을 찾고, F1-maximaisation threshold 가 현재 채점기준에서 우수 \n",
    "#          -> 데이터가, 'label' 균형 관점에서 sampling 되어 -> 'Indepent' 불균형이 큰 문제에서도 \n",
    "#              Threshold 하향 조정이 성능 개선을 이끈 것으로 연관지어 의심해볼 만 함. \n",
    "# ver3. : A 속성에 대한 사람 == 컨텐츠 bool 컬럼 추가 \n",
    "#    ver3.1 : E (순서형, 0~11)속성에 대한 비교 추가 + \n",
    "#    ver3.2 : E 속성 순서형에 대한, Binning 조정 \n",
    "# ver4. : 순서형 자료에 대한, numeric cols 반영 \n",
    "# ver4. : (*Validity 탐색 필요*, 열람시간대, 열람 요일별 판별력 반영) \n",
    "#      -> temporal based-profiling => 단일 변수 분포로는 너무나 판별력(Distinctive power)이 적어보임. \n",
    "#    # ver6. : 똑같이 타고 들어가서, 속성 2개 짜리 별도로 모형에 추가해서 \n",
    "#    #   -> (모형 1: 여러 변수) & (모형 2: 두개 짜리 변수) 에 대한 앙상블해서 스코어 보기 \n",
    "#    #       => 0.70257 \n",
    "#    # ver7. : '열람일시'에 대한 변수 분할로 catboost 태우기 + ver6. 과 앙상블 하기 \n",
    "#    #       => 0.70285\n",
    "# ----------------- 2nd approaches --------------------\n",
    "# ver8. : 파생변수 생성 + best-model-architecture로 적합 \n",
    "#   -> (생성한 속성 pool에서) Feature_selection 하기 \n",
    "# ver9. : 연관규칙분석 -> Metric Exploration "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "### * Validity Test for Data Re-sampling \n",
    "\n",
    "제공된 데이터셋은 'Label' 기준으로, 너무나 잘 균형잡힌 상태(i.e., 열람: 미열람 = 거의 50: 50).   \n",
    "학습 후, Predicted label 결정을 위한 threshold 하향 조정 시에 성능이 더 좋은 현상으로도,   \n",
    "test-set 에서의 label 불균형을 고려해볼 수 있고, 직관적으로도 열람, 미열람 비율이 제공된   \n",
    "데이터셋 만큼이나 균형잡혀 있게 보기 어려울 것으로 판단   \n",
    ">  __독립변수 기준에서의 데이터 re-sampling이, 학습-모형 일반화 측면에서 개선을 보이는지 테스트 수행__ \n",
    "\n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 결과적으로는 ... - \n",
    "    * 모수에 해당할 원-데이터 분포에 대해서 추정 근거가 없이, 특정&일부 독립변수 기준의 up/re-sampling은   \n",
    "        오히려 분포에 대한 왜곡이 커지고 -> 그래서 더욱이, 모델의 학습이 왜곡된 분포에 깊이 최적화 하면서 예측 성능이 더욱 하락했음.    \n",
    "        -> 즉, (Data-resampling + Boosting) 조합이, (특정 변수에 치우친 분포 왜곡 + 그 분포에 대한 과적합) 으로 이어짐. \n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UXQY-42F_gRc"
   },
   "source": [
    "### Drive amount (For Colab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13984,
     "status": "ok",
     "timestamp": 1641196313243,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "ZdtRMd4lglpO",
    "outputId": "686c2fdf-7ab5-4a83-fc23-378955d51639"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive \n",
    "# drive.mount('./content', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1641196313243,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "Txz8cgzbT42g",
    "outputId": "f0472fee-b556-4991-95c9-5d0ce8df3716"
   },
   "outputs": [],
   "source": [
    "# cd ./content/MyDrive/Colab\\ Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1641196313244,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "6b_AmhPjT5Oj",
    "outputId": "691da045-d9a4-432c-d189-49f2bc018c92"
   },
   "outputs": [],
   "source": [
    "# cd ./01.JobCare/scripts/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "881lD0VJ_m2y"
   },
   "source": [
    "### Set Global variables   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1641196316807,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "i2SORQEJMcOT"
   },
   "outputs": [],
   "source": [
    "# DATA_PATH = \"/content/drive/MyDrive/dacon/job_care/data/\"\n",
    "# SUBMIT_PATH = \"/content/drive/MyDrive/dacon/job_care/submit/\"\n",
    "\n",
    "DATA_PATH = '../data/JobCare_data/'\n",
    "SUBMIT_PATH = '../submission/'\n",
    "SEED = 100    # Seed for reproducibility "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J0yyXjHXJMJ1"
   },
   "source": [
    "### catboost install"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11734,
     "status": "ok",
     "timestamp": 1641196328830,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "MQlCENZDe5Eg",
    "outputId": "657fdc4e-5534-4ac8-927d-c3800067a95a"
   },
   "outputs": [],
   "source": [
    "# !pip install catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TKOGpC7sTJLj"
   },
   "source": [
    "### Library import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seaborn\n",
    "# !pip install torch\n",
    "# !pip install imblearn\n",
    "# !pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 399,
     "status": "ok",
     "timestamp": 1641196329222,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "mVGRBMjBTF_D",
    "outputId": "a50756db-0a0a-426f-b546-7d204869f166"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- os: Linux-5.11.0-46-generic-x86_64-with-debian-bullseye-sid\n",
      "- python: 3.7.12 | packaged by conda-forge | (default, Oct 26 2021, 06:08:21) \n",
      "[GCC 9.4.0]\n",
      "- pandas: 1.1.5\n",
      "- numpy: 1.21.5\n",
      "- sklearn: 1.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import platform\n",
    "import random\n",
    "import math\n",
    "import copy \n",
    "from typing import List ,Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold , KFold\n",
    "from sklearn.metrics import f1_score \n",
    "\n",
    "from catboost import Pool, CatBoostClassifier \n",
    "from catboost import FeaturesData\n",
    "\n",
    "import mlxtend\n",
    "from mlxtend.preprocessing import TransactionEncoder \n",
    "from mlxtend.frequent_patterns import fpgrowth\n",
    "\n",
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import torch.nn.init as init\n",
    "\n",
    "print(f\"- os: {platform.platform()}\")\n",
    "print(f\"- python: {sys.version}\")\n",
    "print(f\"- pandas: {pd.__version__}\")\n",
    "print(f\"- numpy: {np.__version__}\")\n",
    "print(f\"- sklearn: {sklearn.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config for pandas displaying options \n",
    "pd.options.display.max_columns = 80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------\n",
    "* __Data Wrangling & Get master tables__  \n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original dataset  \n",
    "data_dir = '../data/JobCare_data/'\n",
    "\n",
    "# path for Prediction.csv  \n",
    "subm_dir = '../submission/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir+'train.csv')\n",
    "test = pd.read_csv(data_dir+'test.csv')\n",
    "\n",
    "# Feature codes \n",
    "feature_D_code = pd.read_csv(data_dir+'속성_D_코드.csv')\n",
    "feature_H_code = pd.read_csv(data_dir+'속성_H_코드.csv')\n",
    "feature_L_code = pd.read_csv(data_dir+'속성_L_코드.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # drop 'Unnamed:5'\n",
    "# feature_D_code = feature_D_code.loc[:, feature_D_code.columns.str.contains('속성 D')]\n",
    "\n",
    "# Rename Columns\n",
    "D_code_map = {\n",
    "    '속성 D 코드': 'D_ALL', \n",
    "    '속성 D 세분류코드': 'D_DET', \n",
    "    '속성 D 소분류코드': 'D_SML', \n",
    "    '속성 D 중분류코드': 'D_MED', \n",
    "    '속성 D 대분류코드': 'D_LAG'\n",
    "}\n",
    "\n",
    "H_code_map = {\n",
    "    '속성 H 코드': 'H_ALL', \n",
    "    '속성 H 중분류코드': 'H_MED', \n",
    "    '속성 H 대분류코드': 'H_LAG'\n",
    "}\n",
    "\n",
    "L_code_map = {\n",
    "    '속성 L 코드': 'L_ALL', \n",
    "    '속성 L 세분류코드': 'L_DET', \n",
    "    '속성 L 소분류코드': 'L_SML', \n",
    "    '속성 L 중분류코드': 'L_MED', \n",
    "    '속성 L 대분류코드': 'L_LAG' \n",
    "}\n",
    "\n",
    "feature_D_code.columns = feature_D_code.columns.map(D_code_map)\n",
    "feature_H_code.columns = feature_H_code.columns.map(H_code_map)\n",
    "feature_L_code.columns = feature_L_code.columns.map(L_code_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datetime handling (str to dt)\n",
    "train['contents_open_dt'] = pd.to_datetime(train['contents_open_dt'], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "test['contents_open_dt'] = pd.to_datetime(test['contents_open_dt'], format=\"%Y-%m-%d %H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Train-set 'contents_open_dt' Min(): 2020-01-01 00:01:03,  Max():2020-11-30 23:59:56\n",
      " *  test-set 'contents_open_dt' Min(): 2020-12-01 00:00:07,  Max():2020-12-31 23:59:08\n"
     ]
    }
   ],
   "source": [
    "print(f\" * Train-set 'contents_open_dt' Min(): {train['contents_open_dt'].min()},  Max():{train['contents_open_dt'].max()}\")\n",
    "print(f\" *  test-set 'contents_open_dt' Min(): {test['contents_open_dt'].min()},  Max():{test['contents_open_dt'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * Master tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create person & contents master tables\n",
    "person_train = train[train.columns[train.columns.str.contains('person_')]]\n",
    "contnt_train = train[train.columns[train.columns.str.contains('contents_')]]\n",
    "\n",
    "# >>> (~person_train.duplicated()).sum() \n",
    "# 300,177    # -> same w/ nunique(person_rn) \n",
    "# >>> (~(contnt_train.drop('contents_open_dt', axis=1).duplicated())).sum()\n",
    "# 283,393    # -> same w/ nunique(contents_rn) \n",
    "\n",
    "person_master = person_train.drop_duplicates(keep='first')\n",
    "contnt_master = contnt_train.drop('contents_open_dt', axis=1).drop_duplicates(keep='first')\n",
    "\n",
    "# Arrange columns' order \n",
    "person_master = pd.concat([person_master['person_rn'], person_master.loc[:, person_master.columns!='person_rn']], axis=1)\n",
    "contnt_master = pd.concat([contnt_master['contents_rn'], contnt_master.loc[:, contnt_master.columns!='contents_rn']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# person_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contnt_master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "* __FeatureGenerator__ \n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> __def getDerivativeFeatures(df):__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def getDerivativeFeatures(df):\n",
    "    # copy DataFrame  \n",
    "    data_df = df.copy()\n",
    "\n",
    "    # ------------------------------------\n",
    "    ### * 'contents_open_dt' -> split into dt.components  \n",
    "    ###    -> Col_prefix : \"open_dt_\"\n",
    "    # ------------------------------------\n",
    "    data_df['open_dt_quarter'] = data_df['contents_open_dt'].dt.quarter\n",
    "    data_df['open_dt_month'] = data_df['contents_open_dt'].dt.month\n",
    "    data_df['open_dt_week'] = data_df['contents_open_dt'].dt.week\n",
    "    data_df['open_dt_day'] = data_df['contents_open_dt'].dt.day\n",
    "    data_df['open_dt_weekday'] = data_df['contents_open_dt'].dt.weekday\n",
    "    # data_df['open_dt_day_name'] = data_df['contents_open_dt'].dt.day_name().str[:3]\n",
    "    data_df['open_dt_hour'] = data_df['contents_open_dt'].dt.hour\n",
    "    data_df['open_dt_minute'] = data_df['contents_open_dt'].dt.minute\n",
    "\n",
    "    # Columns' list \n",
    "    open_dt_cols = list(data_df.columns[data_df.columns.str.contains('open_dt_')])\n",
    "\n",
    "    # ------------------------------------\n",
    "    ### * All combination for each equal-attributes (: [a, a_1], [c], [j, j_1], [e])\n",
    "    ###    -> Col_prefix : \"deriv_\"\n",
    "    # ------------------------------------\n",
    "    # * --- <str> ---\n",
    "    # person_attribute_a & contents_attribute_a\n",
    "    data_df['deriv_a_a'] = data_df['person_attribute_a'].astype(str) + '-' + data_df['contents_attribute_a'].astype(str)\n",
    "\n",
    "    # person_attribute_a & person_attribute_a_1\n",
    "    data_df['deriv_person_a_a_1'] = data_df['person_attribute_a'].astype(str) + '-' + data_df['person_attribute_a_1'].astype(str)\n",
    "\n",
    "    # person_prefer_c & contents_attribute_c\n",
    "    data_df['deriv_c_c'] = data_df['person_prefer_c'].astype(str) + '-' + data_df['contents_attribute_c'].astype(str)\n",
    "\n",
    "    # contents_attribute_j & contents_attribute_j_1\n",
    "    data_df['deriv_contents_j_j_1'] = data_df['contents_attribute_j'].astype(str) + '-' + data_df['contents_attribute_j_1'].astype(str) \n",
    "\n",
    "    # * --- <numeric> ---\n",
    "    # person_prefer_e & contents_attribute_e \n",
    "    data_df['deriv_e_diff'] = data_df['person_prefer_e'] - data_df['contents_attribute_e']\n",
    "\n",
    "    # Columns' list \n",
    "    deriv_cols = list(data_df.columns[data_df.columns.str.contains('deriv_')])    # * All cols \n",
    "\n",
    "    deriv_str_cols = deriv_cols.copy()\n",
    "    deriv_str_cols.remove('deriv_e_diff')    # * str cols \n",
    "    deriv_num_cols = ['deriv_e_diff']    #  * numeric cols \n",
    "    \n",
    "    deriv_cols_dict = {'deriv_str_cols': deriv_str_cols, 'deriv_num_cols': deriv_num_cols}\n",
    "    \n",
    "    # ------------------------------------\n",
    "    ### * '..._yn T/F Combination (: d, h)\n",
    "    ###    -> cols_suffix : \"_yn_comb\"\n",
    "    # ------------------------------------\n",
    "    # d/h_match_yn cols \n",
    "    d_yn_cols = data_df.columns[data_df.columns.str.contains('^d_')]\n",
    "    h_yn_cols = data_df.columns[data_df.columns.str.contains('^h_')]\n",
    "\n",
    "    # create T/F combination col \n",
    "    data_df['d_yn_comb'] = pd.concat([data_df[yn_col_].astype(str).str[0] for yn_col_ in d_yn_cols], axis=1).T.sum()\n",
    "    data_df['h_yn_comb'] = pd.concat([data_df[yn_col_].astype(str).str[0] for yn_col_ in h_yn_cols], axis=1).T.sum()\n",
    "\n",
    "    # expend more combination for 2-feats \n",
    "    data_df['d+h_yn_comb'] = 'D:' + data_df['d_yn_comb'] + '/H:' + data_df['h_yn_comb'] \n",
    "\n",
    "    # Columns' list \n",
    "    yn_comb_cols = list(data_df.columns[data_df.columns.str.contains('_yn_comb')])    # * All cols \n",
    "\n",
    "    # ------------------------------------\n",
    "    ### * \"person_prefer_{H, D}_{1, 2, 3}\" - Coherency \n",
    "    ###    -> cols_format : \"deriv_{D_LAG, D_SML, H_MED, etc.}_sim\"\n",
    "    # ------------------------------------\n",
    "    # *feat- code handling \n",
    "    # -----------------------\n",
    "    feat_D = feature_D_code.astype(str).copy()\n",
    "    feat_H = feature_H_code.astype(str).copy()\n",
    "    feat_L = feature_L_code.astype(str).copy()\n",
    "\n",
    "    feat_D['D_MED'] = feat_D['D_LAG']+'-'+feat_D['D_MED']\n",
    "    feat_D['D_SML'] = feat_D['D_MED']+'-'+feat_D['D_SML']\n",
    "    feat_D['D_DET'] = feat_D['D_SML']+'-'+feat_D['D_DET']\n",
    "\n",
    "    feat_H['H_MED'] = feat_H['H_LAG']+'-'+feat_H['H_MED']\n",
    "\n",
    "    feat_L['L_MED'] = feat_L['L_LAG']+'-'+feat_L['L_MED']\n",
    "    feat_L['L_SML'] = feat_L['L_MED']+'-'+feat_L['L_SML']\n",
    "    feat_L['L_DET'] = feat_L['L_SML']+'-'+feat_L['L_DET']\n",
    "\n",
    "    # * \"deriv_{attribute_class_lv}_sim\"\n",
    "    # -----------------------\n",
    "    # Bucket for deriv \n",
    "    data_df_0 = data_df.copy()\n",
    "    deriv_feat_df = [data_df_0]\n",
    "    deriv_feat_cols_dict = {}    # Columns' dict \n",
    "\n",
    "    # * person_prefer_{d, h}_{1, 2, 3} Comparison cols \n",
    "    for feat_, feat_df, cat_lvs_ in zip([\"D\", 'H'], [feat_D, feat_H], [['D_LAG', 'D_MED', 'D_SML'], ['H_LAG', 'H_MED']]): \n",
    "        person_prefer_cols = data_df.columns[data_df.columns.str.contains(f'person_prefer_{feat_.lower()}')]\n",
    "        # cat_lvs = ['H_LAG', 'H_MED']\n",
    "\n",
    "        person_prefer_frame = []\n",
    "\n",
    "        # for cat_lv_ in cat_lvs: \n",
    "        for cat_lv_ in cat_lvs_: \n",
    "            # Mapping dictionary\n",
    "            cat_lv_mapper = {rec_[f'{feat_}_ALL'] : rec_[cat_lv_] for _, rec_ in feat_df[[f'{feat_}_ALL', cat_lv_]].iterrows()} \n",
    "            # Prepare the [prefer_{1, 2, 3}]\n",
    "            person_prefer_view = data_df[person_prefer_cols].astype(str).copy()\n",
    "            # feat - by target_level - converting  \n",
    "            person_prefer_cnvt = pd.concat([person_prefer_view[col_].map(cat_lv_mapper) for col_ in person_prefer_cols], axis=1)\n",
    "            # Bool for equal-class - <bool> \n",
    "            frames = [(person_prefer_cnvt.iloc[:, lf_]==person_prefer_cnvt.iloc[:, rt_]).rename(f\"deriv_{cat_lv_}_{str(lf_+1)}{str(rt_+1)}\") for lf_, rt_ in [(0, 1), (0, 2), (1, 2)]]\n",
    "            person_prefer_lv_yn = pd.concat(frames, axis=1)\n",
    "\n",
    "            # Similarity Strength -<numeric> \n",
    "            person_prefer_lv_yn[f\"deriv_{cat_lv_}_sim\"] = person_prefer_lv_yn.sum(axis=1)\n",
    "            person_prefer_frame.append(person_prefer_lv_yn)    # Append for \"a-feat-by-each-lvs\"\n",
    "\n",
    "        person_prefer_deriv_df = pd.concat(person_prefer_frame, axis=1)    # Concat for \"a-feat-by-all-lvs\" \n",
    "\n",
    "        # Columns' list \n",
    "        mask_for_num_ = person_prefer_deriv_df.columns.str.contains(\"_sim\")\n",
    "\n",
    "        deriv_feat_cols_dict[f'{feat_}_bool_cols'] = list(person_prefer_deriv_df.columns[~mask_for_num_])\n",
    "        deriv_feat_cols_dict[f'{feat_}_num_cols'] = list(person_prefer_deriv_df.columns[mask_for_num_])\n",
    "\n",
    "        deriv_feat_df.append(person_prefer_deriv_df)\n",
    "\n",
    "    # * concat all-feat \n",
    "    data_df = pd.concat(deriv_feat_df, axis=1)\n",
    "\n",
    "    # ------------------------------------\n",
    "    ### * {[Person-Content] suitability} & {D/H \"Preference-coherency\"} \n",
    "    ###    -> cols_suffix : \"_sim_yn_comb\"\n",
    "    # ------------------------------------\n",
    "\n",
    "    # d/h_match_yn cols \n",
    "    d_sim_cols = data_df.columns[data_df.columns.str.contains('D_..._sim', regex=True)]\n",
    "    h_sim_cols = data_df.columns[data_df.columns.str.contains('H_..._sim', regex=True)]\n",
    "\n",
    "    # T-F Combination \n",
    "    d_yn_comb_with_sim = pd.concat([data_df['d_yn_comb']+'_'+data_df[d_sim_col_].astype(str) for d_sim_col_ in d_sim_cols], axis=1)\n",
    "    h_yn_comb_with_sim = pd.concat([data_df['h_yn_comb']+'_'+data_df[h_sim_col_].astype(str) for h_sim_col_ in h_sim_cols], axis=1)\n",
    "\n",
    "    d_yn_comb_with_sim.columns = d_sim_cols+'_yn_comb'\n",
    "    h_yn_comb_with_sim.columns = h_sim_cols+'_yn_comb'\n",
    "\n",
    "    # append all  \n",
    "    data_df = pd.concat([data_df, d_yn_comb_with_sim, h_yn_comb_with_sim], axis=1)\n",
    "\n",
    "    # Columns' list \n",
    "    sim_yn_comb_cols = d_yn_comb_with_sim.columns.tolist() +  h_yn_comb_with_sim.columns.tolist() \n",
    "    \n",
    "    # ------------------------------------\n",
    "    #### * 'contents_attribute_l' -> split into all class-lv\n",
    "    ###    -> cols_format : \"contents_attribute_L_{LAG, MED}\"\n",
    "    # ------------------------------------\n",
    "    # convert to 'L_LAG' code\n",
    "    attr_l_mapper = {r_[1]['L_ALL']: r_[1]['L_LAG'] for r_ in feat_L[['L_ALL', 'L_LAG']].iterrows()}\n",
    "    data_df['contents_attribute_L_LAG'] = data_df['contents_attribute_l'].astype(str).map(attr_l_mapper)\n",
    "\n",
    "    # convert to 'L_MED' code \n",
    "    attr_l_mapper = {r_[1]['L_ALL']: r_[1]['L_MED'] for r_ in feat_L[['L_ALL', 'L_MED']].iterrows()}\n",
    "    data_df['contents_attribute_L_MED'] = data_df['contents_attribute_l'].astype(str).map(attr_l_mapper)\n",
    "\n",
    "    # Columns' list \n",
    "    attr_l_cols = ['contents_attribute_L_LAG', 'contents_attribute_L_MED']\n",
    "    \n",
    "    # ----------------------------------- \n",
    "    all_deriv_cols_dict = {\n",
    "        \"open_dt_cols\": open_dt_cols, \n",
    "        # \"deriv_cols_dict\": deriv_cols_dict, \n",
    "        'deriv_str_cols': deriv_str_cols, \n",
    "        'deriv_num_cols': deriv_num_cols,\n",
    "        \"yn_comb_cols\": yn_comb_cols, \n",
    "        # \"deriv_feat_cols_dict\": deriv_feat_cols_dict, \n",
    "        \"sim_yn_comb_cols\": sim_yn_comb_cols, \n",
    "        \"attr_l_cols\": attr_l_cols\n",
    "    } \n",
    "    \n",
    "    all_deriv_cols_dict.update(deriv_cols_dict) \n",
    "    all_deriv_cols_dict.update(deriv_feat_cols_dict) \n",
    "    \n",
    "    # ----------------------------------- \n",
    "    return(data_df, all_deriv_cols_dict) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kok/.local/lib/python3.7/site-packages/ipykernel_launcher.py:11: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated.  Please use Series.dt.isocalendar().week instead.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "train_data, deriv_cols = getDerivativeFeatures(train)\n",
    "test_data, _ = getDerivativeFeatures(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * train: (501951, 35)  ->  (501951, 77)  \n",
      " * test : (46404, 34)  ->  (46404, 76)  \n"
     ]
    }
   ],
   "source": [
    "print(f\" * train: {train.shape}  ->  {train_data.shape}  \")\n",
    "print(f\" * test : {test.shape}  ->  {test_data.shape}  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivatives info\n",
    "colnum_max = max([len(cols) for cols in deriv_cols.values()])\n",
    "\n",
    "deriv_cols_info = pd.DataFrame.from_dict(deriv_cols, orient='index', columns=[f\"col_{i+1}\" for i in range(colnum_max)])\n",
    "\n",
    "deriv_cols_info = deriv_cols_info.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>open_dt_cols</th>\n",
       "      <th>deriv_str_cols</th>\n",
       "      <th>deriv_num_cols</th>\n",
       "      <th>yn_comb_cols</th>\n",
       "      <th>sim_yn_comb_cols</th>\n",
       "      <th>attr_l_cols</th>\n",
       "      <th>D_bool_cols</th>\n",
       "      <th>D_num_cols</th>\n",
       "      <th>H_bool_cols</th>\n",
       "      <th>H_num_cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>col_1</th>\n",
       "      <td>open_dt_quarter</td>\n",
       "      <td>deriv_a_a</td>\n",
       "      <td>deriv_e_diff</td>\n",
       "      <td>d_yn_comb</td>\n",
       "      <td>deriv_D_LAG_sim_yn_comb</td>\n",
       "      <td>contents_attribute_L_LAG</td>\n",
       "      <td>deriv_D_LAG_12</td>\n",
       "      <td>deriv_D_LAG_sim</td>\n",
       "      <td>deriv_H_LAG_12</td>\n",
       "      <td>deriv_H_LAG_sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_2</th>\n",
       "      <td>open_dt_month</td>\n",
       "      <td>deriv_person_a_a_1</td>\n",
       "      <td>None</td>\n",
       "      <td>h_yn_comb</td>\n",
       "      <td>deriv_D_MED_sim_yn_comb</td>\n",
       "      <td>contents_attribute_L_MED</td>\n",
       "      <td>deriv_D_LAG_13</td>\n",
       "      <td>deriv_D_MED_sim</td>\n",
       "      <td>deriv_H_LAG_13</td>\n",
       "      <td>deriv_H_MED_sim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_3</th>\n",
       "      <td>open_dt_week</td>\n",
       "      <td>deriv_c_c</td>\n",
       "      <td>None</td>\n",
       "      <td>d+h_yn_comb</td>\n",
       "      <td>deriv_D_SML_sim_yn_comb</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_D_LAG_23</td>\n",
       "      <td>deriv_D_SML_sim</td>\n",
       "      <td>deriv_H_LAG_23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_4</th>\n",
       "      <td>open_dt_day</td>\n",
       "      <td>deriv_contents_j_j_1</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_H_LAG_sim_yn_comb</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_D_MED_12</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_H_MED_12</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_5</th>\n",
       "      <td>open_dt_weekday</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_H_MED_sim_yn_comb</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_D_MED_13</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_H_MED_13</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_6</th>\n",
       "      <td>open_dt_hour</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_D_MED_23</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_H_MED_23</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_7</th>\n",
       "      <td>open_dt_minute</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_D_SML_12</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_8</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_D_SML_13</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>col_9</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>deriv_D_SML_23</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          open_dt_cols        deriv_str_cols deriv_num_cols yn_comb_cols  \\\n",
       "col_1  open_dt_quarter             deriv_a_a   deriv_e_diff    d_yn_comb   \n",
       "col_2    open_dt_month    deriv_person_a_a_1           None    h_yn_comb   \n",
       "col_3     open_dt_week             deriv_c_c           None  d+h_yn_comb   \n",
       "col_4      open_dt_day  deriv_contents_j_j_1           None         None   \n",
       "col_5  open_dt_weekday                  None           None         None   \n",
       "col_6     open_dt_hour                  None           None         None   \n",
       "col_7   open_dt_minute                  None           None         None   \n",
       "col_8             None                  None           None         None   \n",
       "col_9             None                  None           None         None   \n",
       "\n",
       "              sim_yn_comb_cols               attr_l_cols     D_bool_cols  \\\n",
       "col_1  deriv_D_LAG_sim_yn_comb  contents_attribute_L_LAG  deriv_D_LAG_12   \n",
       "col_2  deriv_D_MED_sim_yn_comb  contents_attribute_L_MED  deriv_D_LAG_13   \n",
       "col_3  deriv_D_SML_sim_yn_comb                      None  deriv_D_LAG_23   \n",
       "col_4  deriv_H_LAG_sim_yn_comb                      None  deriv_D_MED_12   \n",
       "col_5  deriv_H_MED_sim_yn_comb                      None  deriv_D_MED_13   \n",
       "col_6                     None                      None  deriv_D_MED_23   \n",
       "col_7                     None                      None  deriv_D_SML_12   \n",
       "col_8                     None                      None  deriv_D_SML_13   \n",
       "col_9                     None                      None  deriv_D_SML_23   \n",
       "\n",
       "            D_num_cols     H_bool_cols       H_num_cols  \n",
       "col_1  deriv_D_LAG_sim  deriv_H_LAG_12  deriv_H_LAG_sim  \n",
       "col_2  deriv_D_MED_sim  deriv_H_LAG_13  deriv_H_MED_sim  \n",
       "col_3  deriv_D_SML_sim  deriv_H_LAG_23             None  \n",
       "col_4             None  deriv_H_MED_12             None  \n",
       "col_5             None  deriv_H_MED_13             None  \n",
       "col_6             None  deriv_H_MED_23             None  \n",
       "col_7             None            None             None  \n",
       "col_8             None            None             None  \n",
       "col_9             None            None             None  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deriv_cols_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "* __Upsampling__   \n",
    "---------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import *\n",
    "from imblearn.over_sampling import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_origin = copy.deepcopy(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Category \\#31: Personalities "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>d_l_match_yn</th>\n",
       "      <th>d_m_match_yn</th>\n",
       "      <th>d_s_match_yn</th>\n",
       "      <th>h_l_match_yn</th>\n",
       "      <th>h_m_match_yn</th>\n",
       "      <th>h_s_match_yn</th>\n",
       "      <th>person_attribute_a</th>\n",
       "      <th>person_attribute_a_1</th>\n",
       "      <th>person_attribute_b</th>\n",
       "      <th>person_prefer_c</th>\n",
       "      <th>person_prefer_d_1</th>\n",
       "      <th>person_prefer_d_2</th>\n",
       "      <th>person_prefer_d_3</th>\n",
       "      <th>person_prefer_e</th>\n",
       "      <th>person_prefer_f</th>\n",
       "      <th>person_prefer_g</th>\n",
       "      <th>person_prefer_h_1</th>\n",
       "      <th>person_prefer_h_2</th>\n",
       "      <th>person_prefer_h_3</th>\n",
       "      <th>contents_attribute_i</th>\n",
       "      <th>contents_attribute_a</th>\n",
       "      <th>contents_attribute_j_1</th>\n",
       "      <th>contents_attribute_j</th>\n",
       "      <th>contents_attribute_c</th>\n",
       "      <th>contents_attribute_k</th>\n",
       "      <th>contents_attribute_l</th>\n",
       "      <th>contents_attribute_d</th>\n",
       "      <th>contents_attribute_m</th>\n",
       "      <th>contents_attribute_e</th>\n",
       "      <th>contents_attribute_h</th>\n",
       "      <th>person_rn</th>\n",
       "      <th>contents_rn</th>\n",
       "      <th>contents_open_dt</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>275</td>\n",
       "      <td>370</td>\n",
       "      <td>369</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>59</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>139</td>\n",
       "      <td>618822</td>\n",
       "      <td>354805</td>\n",
       "      <td>2020-01-17 12:09:36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>114</td>\n",
       "      <td>181</td>\n",
       "      <td>175</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>131</td>\n",
       "      <td>101</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>133</td>\n",
       "      <td>571659</td>\n",
       "      <td>346213</td>\n",
       "      <td>2020-06-18 17:48:52</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>464</td>\n",
       "      <td>175</td>\n",
       "      <td>452</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>54</td>\n",
       "      <td>263</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1600</td>\n",
       "      <td>94</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>399816</td>\n",
       "      <td>206408</td>\n",
       "      <td>2020-07-08 20:00:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>703</td>\n",
       "      <td>705</td>\n",
       "      <td>704</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>227</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>74</td>\n",
       "      <td>827967</td>\n",
       "      <td>572323</td>\n",
       "      <td>2020-01-13 18:09:34</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>275</td>\n",
       "      <td>370</td>\n",
       "      <td>369</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>214</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1608</td>\n",
       "      <td>275</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>74</td>\n",
       "      <td>831614</td>\n",
       "      <td>573899</td>\n",
       "      <td>2020-03-09 20:39:22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501946</th>\n",
       "      <td>501946</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1192</td>\n",
       "      <td>935</td>\n",
       "      <td>1228</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>354</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>65</td>\n",
       "      <td>503156</td>\n",
       "      <td>285850</td>\n",
       "      <td>2020-03-13 12:55:52</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501947</th>\n",
       "      <td>501947</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>118</td>\n",
       "      <td>113</td>\n",
       "      <td>110</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>105</td>\n",
       "      <td>142</td>\n",
       "      <td>95</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>163</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>142</td>\n",
       "      <td>676255</td>\n",
       "      <td>456996</td>\n",
       "      <td>2020-01-20 11:51:51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501948</th>\n",
       "      <td>501948</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>147</td>\n",
       "      <td>46</td>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>127</td>\n",
       "      <td>139</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>438</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>65</td>\n",
       "      <td>484528</td>\n",
       "      <td>293258</td>\n",
       "      <td>2020-08-05 17:27:24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501949</th>\n",
       "      <td>501949</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>147</td>\n",
       "      <td>145</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>251</td>\n",
       "      <td>49</td>\n",
       "      <td>258</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>660</td>\n",
       "      <td>147</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>259</td>\n",
       "      <td>456330</td>\n",
       "      <td>273797</td>\n",
       "      <td>2020-06-15 09:23:21</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501950</th>\n",
       "      <td>501950</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>147</td>\n",
       "      <td>46</td>\n",
       "      <td>145</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>278</td>\n",
       "      <td>31</td>\n",
       "      <td>49</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>786</td>\n",
       "      <td>147</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>289</td>\n",
       "      <td>235596</td>\n",
       "      <td>176650</td>\n",
       "      <td>2020-05-25 14:34:48</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>501951 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  d_l_match_yn  d_m_match_yn  d_s_match_yn  h_l_match_yn  \\\n",
       "0            0          True          True          True         False   \n",
       "1            1         False         False         False          True   \n",
       "2            2         False         False         False          True   \n",
       "3            3         False         False         False          True   \n",
       "4            4          True          True          True         False   \n",
       "...        ...           ...           ...           ...           ...   \n",
       "501946  501946         False         False         False          True   \n",
       "501947  501947          True          True         False          True   \n",
       "501948  501948          True          True          True          True   \n",
       "501949  501949          True         False         False          True   \n",
       "501950  501950          True          True          True          True   \n",
       "\n",
       "        h_m_match_yn  h_s_match_yn  person_attribute_a  person_attribute_a_1  \\\n",
       "0              False         False                   1                     4   \n",
       "1               True         False                   1                     3   \n",
       "2              False         False                   2                     0   \n",
       "3              False         False                   2                     0   \n",
       "4              False         False                   1                     3   \n",
       "...              ...           ...                 ...                   ...   \n",
       "501946         False         False                   1                     1   \n",
       "501947         False         False                   1                     6   \n",
       "501948         False         False                   1                     7   \n",
       "501949         False         False                   1                     1   \n",
       "501950         False         False                   1                     6   \n",
       "\n",
       "        person_attribute_b  person_prefer_c  person_prefer_d_1  \\\n",
       "0                        3                5                275   \n",
       "1                        4                1                114   \n",
       "2                        3                5                464   \n",
       "3                        2                5                703   \n",
       "4                        4                5                275   \n",
       "...                    ...              ...                ...   \n",
       "501946                   2                2               1192   \n",
       "501947                   2                1                118   \n",
       "501948                   4                1                147   \n",
       "501949                   2                1                 46   \n",
       "501950                   3                5                147   \n",
       "\n",
       "        person_prefer_d_2  person_prefer_d_3  person_prefer_e  \\\n",
       "0                     370                369                8   \n",
       "1                     181                175                4   \n",
       "2                     175                452                3   \n",
       "3                     705                704                3   \n",
       "4                     370                369                4   \n",
       "...                   ...                ...              ...   \n",
       "501946                935               1228                3   \n",
       "501947                113                110                4   \n",
       "501948                 46                145                4   \n",
       "501949                147                145                4   \n",
       "501950                 46                145                6   \n",
       "\n",
       "        person_prefer_f  person_prefer_g  person_prefer_h_1  \\\n",
       "0                     1                1                  4   \n",
       "1                     1                1                131   \n",
       "2                     1                1                 54   \n",
       "3                     1                1                 72   \n",
       "4                     1                1                214   \n",
       "...                 ...              ...                ...   \n",
       "501946                1                1                 59   \n",
       "501947                1                1                105   \n",
       "501948                1                1                 59   \n",
       "501949                1                1                251   \n",
       "501950                1                1                278   \n",
       "\n",
       "        person_prefer_h_2  person_prefer_h_3  contents_attribute_i  \\\n",
       "0                      95                 59                     3   \n",
       "1                     101                 96                     1   \n",
       "2                     263                 56                     3   \n",
       "3                     227                  2                     1   \n",
       "4                     210                209                     1   \n",
       "...                   ...                ...                   ...   \n",
       "501946                  4                 95                     3   \n",
       "501947                142                 95                     3   \n",
       "501948                127                139                     3   \n",
       "501949                 49                258                     3   \n",
       "501950                 31                 49                     3   \n",
       "\n",
       "        contents_attribute_a  contents_attribute_j_1  contents_attribute_j  \\\n",
       "0                          3                      10                     2   \n",
       "1                          3                       5                     1   \n",
       "2                          1                      10                     2   \n",
       "3                          3                       5                     1   \n",
       "4                          1                      10                     2   \n",
       "...                      ...                     ...                   ...   \n",
       "501946                     3                       5                     1   \n",
       "501947                     3                      10                     2   \n",
       "501948                     1                       5                     1   \n",
       "501949                     2                       5                     1   \n",
       "501950                     3                       5                     1   \n",
       "\n",
       "        contents_attribute_c  contents_attribute_k  contents_attribute_l  \\\n",
       "0                          1                     2                  1608   \n",
       "1                          1                     2                  1608   \n",
       "2                          1                     1                  1600   \n",
       "3                          1                     2                  1608   \n",
       "4                          1                     2                  1608   \n",
       "...                      ...                   ...                   ...   \n",
       "501946                     1                     2                   354   \n",
       "501947                     1                     2                   163   \n",
       "501948                     1                     2                   438   \n",
       "501949                     1                     2                   660   \n",
       "501950                     1                     2                   786   \n",
       "\n",
       "        contents_attribute_d  contents_attribute_m  contents_attribute_e  \\\n",
       "0                        275                     1                     4   \n",
       "1                        275                     1                     4   \n",
       "2                         94                     1                     4   \n",
       "3                        275                     5                     3   \n",
       "4                        275                     1                     4   \n",
       "...                      ...                   ...                   ...   \n",
       "501946                   147                     1                     5   \n",
       "501947                   120                     1                     4   \n",
       "501948                   147                     2                     7   \n",
       "501949                   147                     3                     4   \n",
       "501950                   147                     2                     5   \n",
       "\n",
       "        contents_attribute_h  person_rn  contents_rn    contents_open_dt  \\\n",
       "0                        139     618822       354805 2020-01-17 12:09:36   \n",
       "1                        133     571659       346213 2020-06-18 17:48:52   \n",
       "2                         53     399816       206408 2020-07-08 20:00:10   \n",
       "3                         74     827967       572323 2020-01-13 18:09:34   \n",
       "4                         74     831614       573899 2020-03-09 20:39:22   \n",
       "...                      ...        ...          ...                 ...   \n",
       "501946                    65     503156       285850 2020-03-13 12:55:52   \n",
       "501947                   142     676255       456996 2020-01-20 11:51:51   \n",
       "501948                    65     484528       293258 2020-08-05 17:27:24   \n",
       "501949                   259     456330       273797 2020-06-15 09:23:21   \n",
       "501950                   289     235596       176650 2020-05-25 14:34:48   \n",
       "\n",
       "        target  \n",
       "0            1  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "...        ...  \n",
       "501946       1  \n",
       "501947       1  \n",
       "501948       1  \n",
       "501949       1  \n",
       "501950       1  \n",
       "\n",
       "[501951 rows x 35 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['person_attribute_a_1', 'person_attribute_b', 'person_prefer_e', 'contents_attribute_e']\n",
    "cat_cols = ['person_attribute_a', 'person_prefer_c', 'person_prefer_d_1', 'person_prefer_d_2', 'person_prefer_d_3',\n",
    "       # 'person_prefer_f', 'person_prefer_g',\n",
    "       'person_prefer_h_1', 'person_prefer_h_2', 'person_prefer_h_3',\n",
    "       'contents_attribute_i', 'contents_attribute_a',\n",
    "       'contents_attribute_j_1', 'contents_attribute_j',\n",
    "       'contents_attribute_c', 'contents_attribute_k', 'contents_attribute_l',\n",
    "       'contents_attribute_d', 'contents_attribute_m', 'contents_attribute_h']\n",
    "bol_cols = ['d_l_match_yn', 'd_m_match_yn', 'd_s_match_yn', 'h_l_match_yn', 'h_m_match_yn', 'h_s_match_yn']\n",
    "idx_cols = ['id', 'person_rn', 'contents_rn'] \n",
    "\n",
    "mis_cols = ['contents_open_dt']\n",
    "\n",
    "trgt_col = ['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[num_cols] = train[num_cols].astype(float)\n",
    "train[cat_cols] = train[cat_cols].astype(str)\n",
    "train[bol_cols] = train[bol_cols].astype(int).astype(str)\n",
    "train[idx_cols] = train[idx_cols].astype(str)\n",
    "train[mis_cols] = train[mis_cols].astype(str)\n",
    "train[trgt_col] = train[trgt_col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_feats = num_cols + cat_cols + bol_cols + idx_cols + mis_cols + trgt_col\n",
    "x_feats = num_cols + cat_cols + bol_cols + trgt_col\n",
    "\n",
    "# ------------------------------\n",
    "upsamp_feat = 'd_s_match_yn'\n",
    "y_feat = x_feats.pop(x_feats.index(upsamp_feat))\n",
    "\n",
    "# ------------------------------\n",
    "\n",
    "X = train[x_feats].values\n",
    "y = train[y_feat]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_samp, y_samp = SMOTE(random_state=4).fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(853388, 28)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_samp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(853388,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_samp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ups = pd.DataFrame(X_samp, columns=x_feats)\n",
    "train_ups[upsamp_feat] = y_samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ups = train_ups.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_ups[num_cols] = train_ups[num_cols].astype(int).astype(float)\n",
    "# train_ups[cat_cols] = train_ups[cat_cols].astype(int).astype(str)\n",
    "# train_ups[bol_cols] = train_ups[bol_cols].astype(int).astype(bool)\n",
    "# # train_ups[idx_cols] = train_ups[idx_cols].astype(str)\n",
    "# # train_ups[mis_cols] = train_ups[mis_cols].astype(str)\n",
    "# train_ups[trgt_col] = train_ups[trgt_col].astype(int).astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "* Adoptation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZR004VEjJmEd"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4107,
     "status": "ok",
     "timestamp": 1641196333653,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "aRdNRpPYTFsD",
    "outputId": "1a1eb527-74d8-403d-9bc8-afee471be5bf"
   },
   "outputs": [],
   "source": [
    "# train_data = pd.read_csv(f'{DATA_PATH}train.csv')\n",
    "test_data = pd.read_csv(f'{DATA_PATH}test.csv')\n",
    "\n",
    "# code_d = pd.read_csv(f'{DATA_PATH}속성_D_코드.csv').iloc[:,:-1]\n",
    "code_d = pd.read_csv(f'{DATA_PATH}속성_D_코드.csv')\n",
    "code_h = pd.read_csv(f'{DATA_PATH}속성_H_코드.csv')\n",
    "code_l = pd.read_csv(f'{DATA_PATH}속성_L_코드.csv')\n",
    "\n",
    "# train_data.shape , test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = copy.deepcopy(train_ups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DA0-1EWg7wcz"
   },
   "source": [
    "### rename columns for handling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1641196333653,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "fIxU3g8ZzRb_"
   },
   "outputs": [],
   "source": [
    "code_d.columns= [\"attribute_d\",\"attribute_d_d\",\"attribute_d_s\",\"attribute_d_m\",\"attribute_d_l\"]\n",
    "# code_h.columns= [\"attribute_h\",\"attribute_h_p\"]\n",
    "code_h.columns= [\"attribute_h\",\"attribute_h_m\",\"attribute_h_l\"]\n",
    "code_l.columns= [\"attribute_l\",\"attribute_l_d\",\"attribute_l_s\",\"attribute_l_m\",\"attribute_l_l\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYinXio-Jztc"
   },
   "source": [
    "### Merge features for Class Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1641196333654,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "x6UbJ3yX70iO"
   },
   "outputs": [],
   "source": [
    "def merge_codes(df:pd.DataFrame,df_code:pd.DataFrame,col:str)->pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    df_code = df_code.copy()\n",
    "    df_code = df_code.add_prefix(f\"{col}_\")\n",
    "    df_code.columns.values[0] = col\n",
    "    return pd.merge(df,df_code,how=\"left\",on=col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N_C3hcvRJ6WF"
   },
   "source": [
    "## Function for Data-Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1641196333654,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "uQaxKG0oTpXb"
   },
   "outputs": [],
   "source": [
    "def preprocess_data(\n",
    "                    df:pd.DataFrame,is_train:bool = True, cols_merge:List[Tuple[str,pd.DataFrame]] = []  , cols_equi:List[Tuple[str,str]]= [] ,\n",
    "                    cols_drop:List[str] = [\"id\",\"person_prefer_f\",\"person_prefer_g\" ,\"contents_open_dt\"]\n",
    "                    )->Tuple[pd.DataFrame,np.ndarray]:\n",
    "    df = df.copy()\n",
    "\n",
    "    y_data = None\n",
    "    \n",
    "    if is_train:\n",
    "        y_data = df[\"target\"].to_numpy()\n",
    "        df = df.drop(columns=\"target\")\n",
    "\n",
    "    for col, df_code in cols_merge:\n",
    "        df = merge_codes(df,df_code,col)\n",
    "\n",
    "    cols = df.select_dtypes(bool).columns.tolist()\n",
    "    df[cols] = df[cols].astype(int)\n",
    "\n",
    "    for col1, col2 in cols_equi:\n",
    "        df[f\"{col1}_{col2}\"] = (df[col1] == df[col2] ).astype(int)\n",
    "\n",
    "    # df = df.drop(columns=cols_drop)\n",
    "    contain_cols = df.columns[~df.columns.isin(cols_drop)]\n",
    "    df = df[contain_cols]\n",
    "        \n",
    "    return (df , y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VKnaH0iFJ_gG"
   },
   "source": [
    "## Set Colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1641196333654,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "r-EDv_4gTsGr"
   },
   "outputs": [],
   "source": [
    "# 소분류 중분류 대분류 속성코드 merge 컬럼명 및 데이터 프레임 리스트\n",
    "cols_merge = [\n",
    "              (\"person_prefer_d_1\" , code_d),\n",
    "              (\"person_prefer_d_2\" , code_d),\n",
    "              (\"person_prefer_d_3\" , code_d),\n",
    "              (\"contents_attribute_d\" , code_d),\n",
    "              (\"person_prefer_h_1\" , code_h),\n",
    "              (\"person_prefer_h_2\" , code_h),\n",
    "              (\"person_prefer_h_3\" , code_h),\n",
    "              (\"contents_attribute_h\" , code_h),\n",
    "              (\"contents_attribute_l\" , code_l),\n",
    "]\n",
    "\n",
    "# 회원 속성과 콘텐츠 속성의 동일한 코드 여부에 대한 컬럼명 리스트\n",
    "cols_equi = [\n",
    "\n",
    "    (\"contents_attribute_c\",\"person_prefer_c\"),\n",
    "    # (\"contents_attribute_e\",\"person_prefer_e\"),    # disable - Ver. 3-1 \n",
    "\n",
    "    (\"person_prefer_d_1_attribute_d_s\" , \"contents_attribute_d_attribute_d_s\"),   # Additional \n",
    "    (\"person_prefer_d_1_attribute_d_m\" , \"contents_attribute_d_attribute_d_m\"),   # Additional \n",
    "    (\"person_prefer_d_1_attribute_d_l\" , \"contents_attribute_d_attribute_d_l\"),   # Additional \n",
    "    (\"person_prefer_d_2_attribute_d_s\" , \"contents_attribute_d_attribute_d_s\"),\n",
    "    (\"person_prefer_d_2_attribute_d_m\" , \"contents_attribute_d_attribute_d_m\"),\n",
    "    (\"person_prefer_d_2_attribute_d_l\" , \"contents_attribute_d_attribute_d_l\"),\n",
    "    (\"person_prefer_d_3_attribute_d_s\" , \"contents_attribute_d_attribute_d_s\"),\n",
    "    (\"person_prefer_d_3_attribute_d_m\" , \"contents_attribute_d_attribute_d_m\"),\n",
    "    (\"person_prefer_d_3_attribute_d_l\" , \"contents_attribute_d_attribute_d_l\"),\n",
    "\n",
    "    # (\"person_prefer_h_1_attribute_h_p\" , \"contents_attribute_h_attribute_h_p\"),\n",
    "    # (\"person_prefer_h_2_attribute_h_p\" , \"contents_attribute_h_attribute_h_p\"),\n",
    "    # (\"person_prefer_h_3_attribute_h_p\" , \"contents_attribute_h_attribute_h_p\"),\n",
    "    (\"person_prefer_h_1_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n",
    "    (\"person_prefer_h_1_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n",
    "    (\"person_prefer_h_2_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n",
    "    (\"person_prefer_h_2_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"),\n",
    "    (\"person_prefer_h_3_attribute_h_m\" , \"contents_attribute_h_attribute_h_m\"),\n",
    "    (\"person_prefer_h_3_attribute_h_l\" , \"contents_attribute_h_attribute_h_l\"), \n",
    "    # Additional attr_'A' - in ver3. / in ver5.\n",
    "    (\"contents_attribute_a\",\"person_attribute_a\")\n",
    "    \n",
    "]\n",
    "\n",
    "# 학습에 필요없는 컬럼 리스트\n",
    "cols_drop = [\"id\",\"person_prefer_f\",\"person_prefer_g\" ,\"contents_open_dt\", \"contents_rn\", ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dIIYFriJKjdc"
   },
   "source": [
    "## Preprocessing for Train/Test-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2627,
     "status": "ok",
     "timestamp": 1641196370723,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "xeHhs6pzTxvz",
    "outputId": "4ebcd9b9-e18b-4a2e-ff82-5b9e6f52058d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((853388, 73), (853388,), (46404, 74))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train, y_train = preprocess_data(train_data, cols_merge = cols_merge , cols_equi= cols_equi , cols_drop = cols_drop)\n",
    "x_test, _ = preprocess_data(test_data,is_train = False, cols_merge = cols_merge , cols_equi= cols_equi  , cols_drop = cols_drop)\n",
    "x_train.shape , y_train.shape , x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1641196370725,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "TfO2jWfmsnhl"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EyqIVFZWsnbS"
   },
   "source": [
    "### Ver 3.1 - 속성 e 에 대한 수치형 편차 비교 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1641196372534,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "KTdMsQR5snUk"
   },
   "outputs": [],
   "source": [
    "# attr_e_cols = x_train.columns[x_train.columns.str.contains('_e')]\n",
    "# x_train[attr_e_cols]\n",
    "# attr_e_diff = x_train['person_prefer_e'] - x_train['contents_attribute_e']\n",
    "# attr_e_diff_abs = (attr_e_diff).abs()\n",
    "\n",
    "# 사람/컨텐츠 사이 e에 대한 거리 값만 보존 \n",
    "x_train['attribute_e_diff_abs'] = (x_train['person_prefer_e'] - x_train['contents_attribute_e']).abs()\n",
    "x_test['attribute_e_diff_abs'] = (x_test['person_prefer_e'] - x_test['contents_attribute_e']).abs()\n",
    "# x_train['attribute_e_diff_abs'] = (x_train['person_prefer_e'] - x_train['contents_attribute_e'])\n",
    "# x_test['attribute_e_diff_abs'] = (x_test['person_prefer_e'] - x_test['contents_attribute_e'])\n",
    "# 원본 수치는 모두 제거 \n",
    "del x_train['person_prefer_e']\n",
    "del x_train['contents_attribute_e']\n",
    "del x_test['person_prefer_e']\n",
    "del x_test['contents_attribute_e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 350,
     "status": "ok",
     "timestamp": 1641196956312,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "2qacG6fVTZEO",
    "outputId": "4da22c03-70e8-418e-d261-7a021bb6d827"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         4.0\n",
       "1         0.0\n",
       "2         1.0\n",
       "3         0.0\n",
       "4         0.0\n",
       "         ... \n",
       "853383    2.0\n",
       "853384    0.0\n",
       "853385    1.0\n",
       "853386    1.0\n",
       "853387    1.0\n",
       "Name: attribute_e_diff_abs, Length: 853388, dtype: float64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train['attribute_e_diff_abs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okHoydC0KoLs"
   },
   "source": [
    "## Feature Grouping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 401,
     "status": "ok",
     "timestamp": 1641196378261,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "YBHeYPx4gHZv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43\n"
     ]
    }
   ],
   "source": [
    "# cat_features = x_train.columns[x_train.nunique() > 2].tolist()    # (>) 말고 (>=) 이거도 테스트 해야 함, (==2 <= 경우는, True/False도 포함 )\n",
    "cat_features = x_train.columns[x_train.nunique() > 2].tolist()    # - in ver5  \n",
    "\n",
    "# * 명목형/ 순서형 구분하기 - in ver4. \n",
    "# ordinal_feats = ['person_attribute_a_1', 'person_attribute_b', 'person_prefer_e', 'contents_prefer_e']\n",
    "# * 명목형/ 순서형 구분하기 - in ver3.1  \n",
    "# ordinal_feats = ['attribute_e_diff_abs']\n",
    "# * 명목형/ 순서형 구분하기 - in ver5  \n",
    "ordinal_feats = ['person_attribute_a_1', 'person_attribute_b', 'attribute_e_diff_abs']\n",
    "\n",
    "# 범주형 속성에서, 수치형 속성 제거 \n",
    "cat_features = list(set(cat_features) - set(ordinal_feats))\n",
    "\n",
    "print(len(cat_features))    # <- 사용되는 범주형 변수 갯수 \n",
    "# cat_features = x_train.columns[x_train.nunique() > 2].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1641197142269,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "m57Ld3RX973c"
   },
   "outputs": [],
   "source": [
    "# ordinal_feats -> to -> 'float' type \n",
    "x_train[ordinal_feats] = x_train[ordinal_feats].astype(np.float32)\n",
    "x_test[ordinal_feats] = x_test[ordinal_feats].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "51s5rZfK99bJ"
   },
   "outputs": [],
   "source": [
    "# x_train = x_train.round(0)\n",
    "# x_test = x_test.round(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6aGHnC9OK63t"
   },
   "source": [
    "## Parameter setting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 360,
     "status": "ok",
     "timestamp": 1641197159918,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "mkdxBRJMgtzP"
   },
   "outputs": [],
   "source": [
    "is_holdout = False\n",
    "n_splits = 5\n",
    "iterations = 10000\n",
    "# iterations = 3600\n",
    "patience = 50\n",
    "learning_rate=0.075\n",
    "\n",
    "max_ctr_complexity = 6\n",
    "min_data_in_leaf = 10\n",
    "\n",
    "cv = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDG1B-tzLCuM"
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(CatBoostClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "0:\tlearn: 0.6096936\ttest: 0.6109032\tbest: 0.6109032 (0)\ttotal: 86ms\tremaining: 14m 20s\n",
      "400:\tlearn: 0.7604676\ttest: 0.8004113\tbest: 0.8004113 (400)\ttotal: 34.5s\tremaining: 13m 45s\n",
      "800:\tlearn: 0.7709754\ttest: 0.8091072\tbest: 0.8091072 (800)\ttotal: 1m 8s\tremaining: 13m 11s\n",
      "1200:\tlearn: 0.7773415\ttest: 0.8128812\tbest: 0.8128909 (1197)\ttotal: 1m 43s\tremaining: 12m 36s\n",
      "1600:\tlearn: 0.7819937\ttest: 0.8146911\tbest: 0.8146911 (1600)\ttotal: 2m 17s\tremaining: 12m 1s\n",
      "2000:\tlearn: 0.7860966\ttest: 0.8160514\tbest: 0.8160514 (2000)\ttotal: 2m 51s\tremaining: 11m 26s\n",
      "2400:\tlearn: 0.7899029\ttest: 0.8170342\tbest: 0.8170342 (2400)\ttotal: 3m 25s\tremaining: 10m 51s\n",
      "2800:\tlearn: 0.7932531\ttest: 0.8177810\tbest: 0.8177814 (2799)\ttotal: 4m\tremaining: 10m 17s\n",
      "3200:\tlearn: 0.7966535\ttest: 0.8187046\tbest: 0.8187068 (3198)\ttotal: 4m 34s\tremaining: 9m 43s\n",
      "3600:\tlearn: 0.7996124\ttest: 0.8191912\tbest: 0.8191996 (3594)\ttotal: 5m 8s\tremaining: 9m 8s\n",
      "4000:\tlearn: 0.8025452\ttest: 0.8195798\tbest: 0.8195871 (3992)\ttotal: 5m 42s\tremaining: 8m 34s\n",
      "4400:\tlearn: 0.8054869\ttest: 0.8201634\tbest: 0.8201657 (4395)\ttotal: 6m 17s\tremaining: 7m 59s\n",
      "4800:\tlearn: 0.8083746\ttest: 0.8206202\tbest: 0.8206249 (4782)\ttotal: 6m 51s\tremaining: 7m 25s\n",
      "bestTest = 0.8208600283\n",
      "bestIteration = 5010\n",
      "Shrink model to first 5011 iterations.\n",
      "==================================================\n",
      "0:\tlearn: 0.6118007\ttest: 0.6146434\tbest: 0.6146434 (0)\ttotal: 92.6ms\tremaining: 15m 25s\n",
      "400:\tlearn: 0.7611773\ttest: 0.8006911\tbest: 0.8006911 (400)\ttotal: 34.6s\tremaining: 13m 48s\n",
      "800:\tlearn: 0.7712469\ttest: 0.8086279\tbest: 0.8086293 (799)\ttotal: 1m 8s\tremaining: 13m 8s\n",
      "1200:\tlearn: 0.7770331\ttest: 0.8116719\tbest: 0.8116783 (1199)\ttotal: 1m 42s\tremaining: 12m 32s\n",
      "1600:\tlearn: 0.7818515\ttest: 0.8139142\tbest: 0.8139169 (1594)\ttotal: 2m 16s\tremaining: 11m 57s\n",
      "2000:\tlearn: 0.7860875\ttest: 0.8154711\tbest: 0.8154754 (1995)\ttotal: 2m 50s\tremaining: 11m 23s\n",
      "2400:\tlearn: 0.7895678\ttest: 0.8162599\tbest: 0.8162599 (2400)\ttotal: 3m 24s\tremaining: 10m 48s\n",
      "2800:\tlearn: 0.7930297\ttest: 0.8172314\tbest: 0.8172314 (2800)\ttotal: 3m 58s\tremaining: 10m 14s\n",
      "3200:\tlearn: 0.7963577\ttest: 0.8180538\tbest: 0.8180603 (3195)\ttotal: 4m 33s\tremaining: 9m 40s\n",
      "3600:\tlearn: 0.7993569\ttest: 0.8185816\tbest: 0.8185848 (3597)\ttotal: 5m 7s\tremaining: 9m 5s\n",
      "4000:\tlearn: 0.8024732\ttest: 0.8193881\tbest: 0.8193881 (4000)\ttotal: 5m 41s\tremaining: 8m 31s\n",
      "4400:\tlearn: 0.8054168\ttest: 0.8198928\tbest: 0.8198937 (4384)\ttotal: 6m 15s\tremaining: 7m 57s\n",
      "4800:\tlearn: 0.8080986\ttest: 0.8202686\tbest: 0.8202750 (4786)\ttotal: 6m 49s\tremaining: 7m 23s\n",
      "5200:\tlearn: 0.8107396\ttest: 0.8206052\tbest: 0.8206052 (5200)\ttotal: 7m 24s\tremaining: 6m 49s\n",
      "5600:\tlearn: 0.8133717\ttest: 0.8209934\tbest: 0.8209962 (5598)\ttotal: 7m 58s\tremaining: 6m 15s\n",
      "bestTest = 0.8210325539\n",
      "bestIteration = 5664\n",
      "Shrink model to first 5665 iterations.\n",
      "==================================================\n",
      "0:\tlearn: 0.6127490\ttest: 0.6138635\tbest: 0.6138635 (0)\ttotal: 92.6ms\tremaining: 15m 25s\n",
      "400:\tlearn: 0.7611661\ttest: 0.7991689\tbest: 0.7991716 (399)\ttotal: 34.6s\tremaining: 13m 47s\n",
      "800:\tlearn: 0.7718318\ttest: 0.8078372\tbest: 0.8078372 (800)\ttotal: 1m 8s\tremaining: 13m 10s\n",
      "1200:\tlearn: 0.7776644\ttest: 0.8109391\tbest: 0.8109391 (1200)\ttotal: 1m 43s\tremaining: 12m 36s\n",
      "1600:\tlearn: 0.7820899\ttest: 0.8125930\tbest: 0.8125930 (1600)\ttotal: 2m 17s\tremaining: 12m 1s\n",
      "2000:\tlearn: 0.7861282\ttest: 0.8139737\tbest: 0.8139749 (1998)\ttotal: 2m 51s\tremaining: 11m 26s\n",
      "2400:\tlearn: 0.7898258\ttest: 0.8150938\tbest: 0.8150939 (2398)\ttotal: 3m 26s\tremaining: 10m 52s\n",
      "2800:\tlearn: 0.7932305\ttest: 0.8157740\tbest: 0.8157752 (2799)\ttotal: 4m\tremaining: 10m 18s\n",
      "3200:\tlearn: 0.7964889\ttest: 0.8166217\tbest: 0.8166236 (3180)\ttotal: 4m 34s\tremaining: 9m 43s\n",
      "3600:\tlearn: 0.7996548\ttest: 0.8172897\tbest: 0.8172957 (3589)\ttotal: 5m 9s\tremaining: 9m 9s\n",
      "4000:\tlearn: 0.8027220\ttest: 0.8180252\tbest: 0.8180384 (3959)\ttotal: 5m 43s\tremaining: 8m 35s\n",
      "4400:\tlearn: 0.8057519\ttest: 0.8184870\tbest: 0.8184936 (4387)\ttotal: 6m 18s\tremaining: 8m 1s\n",
      "4800:\tlearn: 0.8084666\ttest: 0.8188502\tbest: 0.8188576 (4792)\ttotal: 6m 52s\tremaining: 7m 27s\n",
      "5200:\tlearn: 0.8111518\ttest: 0.8193024\tbest: 0.8193058 (5198)\ttotal: 7m 27s\tremaining: 6m 53s\n",
      "5600:\tlearn: 0.8138968\ttest: 0.8197741\tbest: 0.8197765 (5594)\ttotal: 8m 2s\tremaining: 6m 18s\n",
      "bestTest = 0.8198061585\n",
      "bestIteration = 5621\n",
      "Shrink model to first 5622 iterations.\n",
      "==================================================\n",
      "0:\tlearn: 0.6066005\ttest: 0.6108055\tbest: 0.6108055 (0)\ttotal: 93.9ms\tremaining: 15m 38s\n",
      "400:\tlearn: 0.7598113\ttest: 0.7994138\tbest: 0.7994138 (400)\ttotal: 34.4s\tremaining: 13m 43s\n",
      "800:\tlearn: 0.7706295\ttest: 0.8085476\tbest: 0.8085476 (800)\ttotal: 1m 8s\tremaining: 13m 11s\n",
      "1200:\tlearn: 0.7767567\ttest: 0.8121477\tbest: 0.8121477 (1200)\ttotal: 1m 43s\tremaining: 12m 36s\n",
      "1600:\tlearn: 0.7815341\ttest: 0.8142156\tbest: 0.8142156 (1600)\ttotal: 2m 17s\tremaining: 12m\n",
      "2000:\tlearn: 0.7857402\ttest: 0.8157431\tbest: 0.8157455 (1997)\ttotal: 2m 51s\tremaining: 11m 24s\n",
      "2400:\tlearn: 0.7892387\ttest: 0.8164639\tbest: 0.8164670 (2354)\ttotal: 3m 25s\tremaining: 10m 49s\n",
      "2800:\tlearn: 0.7927707\ttest: 0.8174137\tbest: 0.8174151 (2799)\ttotal: 3m 59s\tremaining: 10m 16s\n",
      "3200:\tlearn: 0.7960117\ttest: 0.8180183\tbest: 0.8180183 (3200)\ttotal: 4m 34s\tremaining: 9m 42s\n",
      "3600:\tlearn: 0.7992005\ttest: 0.8187014\tbest: 0.8187036 (3595)\ttotal: 5m 8s\tremaining: 9m 8s\n",
      "4000:\tlearn: 0.8022225\ttest: 0.8191729\tbest: 0.8191817 (3993)\ttotal: 5m 42s\tremaining: 8m 34s\n",
      "4400:\tlearn: 0.8051652\ttest: 0.8197043\tbest: 0.8197043 (4400)\ttotal: 6m 17s\tremaining: 8m\n",
      "4800:\tlearn: 0.8079808\ttest: 0.8202611\tbest: 0.8202611 (4800)\ttotal: 6m 51s\tremaining: 7m 25s\n",
      "5200:\tlearn: 0.8107367\ttest: 0.8206449\tbest: 0.8206472 (5197)\ttotal: 7m 25s\tremaining: 6m 51s\n",
      "5600:\tlearn: 0.8133739\ttest: 0.8209756\tbest: 0.8209756 (5600)\ttotal: 8m\tremaining: 6m 17s\n",
      "6000:\tlearn: 0.8158467\ttest: 0.8212675\tbest: 0.8212678 (5999)\ttotal: 8m 34s\tremaining: 5m 42s\n",
      "6400:\tlearn: 0.8184099\ttest: 0.8216358\tbest: 0.8216419 (6398)\ttotal: 9m 8s\tremaining: 5m 8s\n",
      "bestTest = 0.8216703236\n",
      "bestIteration = 6419\n",
      "Shrink model to first 6420 iterations.\n",
      "==================================================\n",
      "0:\tlearn: 0.6109351\ttest: 0.6130788\tbest: 0.6130788 (0)\ttotal: 92.1ms\tremaining: 15m 21s\n",
      "400:\tlearn: 0.7600539\ttest: 0.7985537\tbest: 0.7985537 (400)\ttotal: 34.8s\tremaining: 13m 52s\n",
      "800:\tlearn: 0.7704532\ttest: 0.8067711\tbest: 0.8067711 (800)\ttotal: 1m 9s\tremaining: 13m 16s\n",
      "1200:\tlearn: 0.7767136\ttest: 0.8104322\tbest: 0.8104348 (1199)\ttotal: 1m 43s\tremaining: 12m 38s\n",
      "1600:\tlearn: 0.7813940\ttest: 0.8124204\tbest: 0.8124204 (1600)\ttotal: 2m 18s\tremaining: 12m 4s\n",
      "2000:\tlearn: 0.7855532\ttest: 0.8139181\tbest: 0.8139181 (2000)\ttotal: 2m 52s\tremaining: 11m 29s\n",
      "2400:\tlearn: 0.7890948\ttest: 0.8149258\tbest: 0.8149294 (2399)\ttotal: 3m 26s\tremaining: 10m 53s\n",
      "2800:\tlearn: 0.7925777\ttest: 0.8157622\tbest: 0.8157623 (2799)\ttotal: 4m\tremaining: 10m 18s\n",
      "3200:\tlearn: 0.7960408\ttest: 0.8167362\tbest: 0.8167376 (3184)\ttotal: 4m 35s\tremaining: 9m 44s\n",
      "3600:\tlearn: 0.7991616\ttest: 0.8174322\tbest: 0.8174335 (3595)\ttotal: 5m 9s\tremaining: 9m 9s\n",
      "4000:\tlearn: 0.8021526\ttest: 0.8179849\tbest: 0.8179882 (3989)\ttotal: 5m 43s\tremaining: 8m 35s\n",
      "4400:\tlearn: 0.8050000\ttest: 0.8184200\tbest: 0.8184256 (4394)\ttotal: 6m 17s\tremaining: 8m\n",
      "4800:\tlearn: 0.8078492\ttest: 0.8189262\tbest: 0.8189301 (4797)\ttotal: 6m 52s\tremaining: 7m 26s\n",
      "5200:\tlearn: 0.8104995\ttest: 0.8192955\tbest: 0.8193001 (5191)\ttotal: 7m 26s\tremaining: 6m 51s\n",
      "bestTest = 0.8193147182\n",
      "bestIteration = 5209\n",
      "Shrink model to first 5210 iterations.\n"
     ]
    }
   ],
   "source": [
    "# scores = []\n",
    "scores_F1 = []\n",
    "scores_AUC = []\n",
    "models = []\n",
    "\n",
    "for tri, vai in cv.split(x_train):\n",
    "    print(\"=\"*50)\n",
    "    # # -----------------------------------------------------------\n",
    "    # # * Assign train/valid set -> CatBoost.FeatureData()\n",
    "    # x_tra = x_train.iloc[tri].copy() \n",
    "    # train_labels = y_train[tri].copy() \n",
    "    # x_val = x_train.iloc[vai].copy() \n",
    "    # valid_labels = y_train[vai].copy() \n",
    "    \n",
    "    # train_data = FeaturesData(\n",
    "    #     num_feature_data=x_tra[ordinal_feats].astype(np.float32).values,\n",
    "    #     cat_feature_data=x_tra[cat_features].astype('object').values,\n",
    "    #     num_feature_names=ordinal_feats, \n",
    "    #     cat_feature_names=cat_features\n",
    "    #     )\n",
    "    \n",
    "    # valid_data = FeaturesData(\n",
    "    #     num_feature_data=x_val[ordinal_feats].astype(np.float32).values,\n",
    "    #     cat_feature_data=x_val[cat_features].astype('object').values,\n",
    "    #     num_feature_names=ordinal_feats, \n",
    "    #     cat_feature_names=cat_features\n",
    "    #     )\n",
    "    # # -----------------------------------------------------------\n",
    "    # -----------------------------------------------------------\n",
    "    # * Assign train/valid set -> CatBoost.FeatureData()\n",
    "    x_tra = x_train.iloc[tri].copy() \n",
    "    train_labels = y_train[tri].copy() \n",
    "    x_val = x_train.iloc[vai].copy() \n",
    "    valid_labels = y_train[vai].copy() \n",
    "    \n",
    "    train_data = Pool(\n",
    "        data=FeaturesData(\n",
    "            num_feature_data=x_tra[ordinal_feats].astype(np.float32).values,\n",
    "            # num_feature_data=x_tra[ordinal_feats].values,\n",
    "            # cat_feature_data=x_tra[cat_features].astype('object').values,    # [342, 0, ...], dtype=object <- 에러남\n",
    "            cat_feature_data=x_tra[cat_features].astype(str).values,    # ['342', '0', ...], dtype=object <- 속도 많이 걸림 \n",
    "            # cat_feature_data=x_tra[cat_features].values,\n",
    "            num_feature_names=ordinal_feats, \n",
    "            cat_feature_names=cat_features\n",
    "            ),\n",
    "        label=train_labels\n",
    "    )\n",
    "    \n",
    "    valid_data = Pool(\n",
    "        data=FeaturesData(\n",
    "            num_feature_data=x_val[ordinal_feats].astype(np.float32).values,\n",
    "            # num_feature_data=x_val[ordinal_feats].values,\n",
    "            # cat_feature_data=x_val[cat_features].astype('object').values,\n",
    "            cat_feature_data=x_val[cat_features].astype(str).values,\n",
    "            # cat_feature_data=x_val[cat_features].values,\n",
    "            num_feature_names=ordinal_feats, \n",
    "            cat_feature_names=cat_features\n",
    "            ),\n",
    "        label=valid_labels\n",
    "    )\n",
    "    # -----------------------------------------------------------\n",
    "    \n",
    "    # list for prediction \n",
    "    preds = []\n",
    "\n",
    "    # * ver.2 : metric = 'AUC'\n",
    "    # model = CatBoostClassifier(iterations=iterations,random_state=SEED,task_type=\"GPU\",eval_metric=\"AUC\",cat_features=cat_features,one_hot_max_size=4)\n",
    "    model = CatBoostClassifier(iterations=iterations, \n",
    "                               random_state=SEED, \n",
    "                               task_type=\"GPU\", \n",
    "                               eval_metric=\"AUC\", \n",
    "                               one_hot_max_size=4,\n",
    "                               # ----------------------------\n",
    "                               learning_rate=learning_rate,\n",
    "                               max_ctr_complexity=max_ctr_complexity, \n",
    "                               min_data_in_leaf=min_data_in_leaf\n",
    "                              )\n",
    "    # model = CatBoostClassifier(iterations=iterations, random_state=SEED, # task_type=\"GPU\", \n",
    "    #                            eval_metric=\"AUC\", cat_features=cat_features, one_hot_max_size=4)\n",
    "    \n",
    "    # model.fit(x_train.iloc[tri], y_train[tri], \n",
    "    # model.fit(train_data, train_labels, \n",
    "    model.fit(train_data, \n",
    "            # eval_set=[(x_train.iloc[vai], y_train[vai])], \n",
    "            # eval_set=[(valid_data, valid_labels)], \n",
    "            eval_set=valid_data, \n",
    "            early_stopping_rounds=patience, \n",
    "            verbose = 400\n",
    "        )\n",
    "    \n",
    "    models.append(model)\n",
    "    # scores_F1.append(model.get_best_score()[\"validation\"][\"F1\"])\n",
    "    # scores_F1.append(f1_score(y_train[vai], model.predict(x_train.iloc[vai])))\n",
    "    scores_F1.append(f1_score(valid_labels, model.predict(valid_data)))\n",
    "    scores_AUC.append(model.get_best_score()[\"validation\"][\"AUC\"])\n",
    "    \n",
    "    if is_holdout:\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_a2_yqqLF9M"
   },
   "source": [
    "## CV Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "LpumWH7BpaAT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * scores_F1 : [0.7680229525299948, 0.7675531415823108, 0.7672518885126335, 0.7686766621515723, 0.7666229631017043]\n",
      " * The Avg. of F1 scores : 0.7676255215756431\n",
      " * scores_AUC : [0.8208600282669067, 0.8210325539112091, 0.8198061585426331, 0.8216703236103058, 0.81931471824646]\n",
      " * The Avg. of AUC scores : 0.820536756515503\n"
     ]
    }
   ],
   "source": [
    "print(f\" * scores_F1 : {scores_F1}\")\n",
    "print(f\" * The Avg. of F1 scores : {np.mean(scores_F1)}\")\n",
    "\n",
    "print(f\" * scores_AUC : {scores_AUC}\")\n",
    "print(f\" * The Avg. of AUC scores : {np.mean(scores_AUC)}\")\n",
    "#  * scores_F1 : [0.6842252192412471, 0.6844616302110387, 0.6835157199930519, 0.6803709668031276, 0.6793908668805676]\n",
    "#  * The Avg. of F1 scores : 0.6823928806258065\n",
    "#  * scores_AUC : [0.7385962903499603, 0.7373865246772766, 0.7384682893753052, 0.7354912161827087, 0.735406219959259]\n",
    "#  * The Avg. of AUC scores : 0.7370697081089019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NT9AExaEZRFQ"
   },
   "source": [
    "### Threshold Optimization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_by_thres_ = [] \n",
    "\n",
    "for i,(tri, vai) in enumerate( cv.split(x_train)):\n",
    "    # pred_proba = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "    # -----------------------------------------------------------\n",
    "    # * Assign train/valid set -> CatBoost.FeatureData()\n",
    "    x_tra = x_train.iloc[tri].copy() \n",
    "    train_labels = y_train[tri].copy() \n",
    "    x_val = x_train.iloc[vai].copy() \n",
    "    valid_labels = y_train[vai].copy() \n",
    "    \n",
    "    train_data = Pool(\n",
    "        data=FeaturesData(\n",
    "            num_feature_data=x_tra[ordinal_feats].astype(np.float32).values,\n",
    "            # num_feature_data=x_tra[ordinal_feats].values,\n",
    "            # cat_feature_data=x_tra[cat_features].astype('object').values,    # [342, 0, ...], dtype=object <- 에러남\n",
    "            cat_feature_data=x_tra[cat_features].astype(str).values,    # ['342', '0', ...], dtype=object <- 속도 많이 걸림 \n",
    "            # cat_feature_data=x_tra[cat_features].values,\n",
    "            num_feature_names=ordinal_feats, \n",
    "            cat_feature_names=cat_features\n",
    "            ),\n",
    "        label=train_labels\n",
    "    )\n",
    "    \n",
    "    valid_data = Pool(\n",
    "        data=FeaturesData(\n",
    "            num_feature_data=x_val[ordinal_feats].astype(np.float32).values,\n",
    "            # num_feature_data=x_val[ordinal_feats].values,\n",
    "            # cat_feature_data=x_val[cat_features].astype('object').values,\n",
    "            cat_feature_data=x_val[cat_features].astype(str).values,\n",
    "            # cat_feature_data=x_val[cat_features].values,\n",
    "            num_feature_names=ordinal_feats, \n",
    "            cat_feature_names=cat_features\n",
    "            ),\n",
    "        label=valid_labels\n",
    "    )\n",
    "    # -----------------------------------------------------------\n",
    "    pred_proba = models[i].predict_proba(valid_data)[:, 1]\n",
    "\n",
    "    sco_by_thres_ = []\n",
    "    for thrs_ in range(10, 90, 5):    # threshold : 0.1 ~ 0.85 \n",
    "\n",
    "        threshold = thrs_/100\n",
    "        pred = np.where(pred_proba >= threshold , 1, 0)\n",
    "        score = f1_score(y_train[vai],pred)\n",
    "\n",
    "        sco_by_thres_.append(score)\n",
    "    \n",
    "    scores_by_thres_.append(sco_by_thres_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "ifuKSAE_ZQ6f"
   },
   "outputs": [],
   "source": [
    "# scores_by_thres_ = [] \n",
    "\n",
    "# for i,(tri, vai) in enumerate( cv.split(x_train)):\n",
    "#     pred_proba = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "\n",
    "#     sco_by_thres_ = []\n",
    "#     for thrs_ in range(10, 90, 5):    # threshold : 0.1 ~ 0.85 \n",
    "\n",
    "#         threshold = thrs_/100\n",
    "#         pred = np.where(pred_proba >= threshold , 1, 0)\n",
    "#         score = f1_score(y_train[vai],pred)\n",
    "\n",
    "#         sco_by_thres_.append(score)\n",
    "\n",
    "#     scores_by_thres_.append(sco_by_thres_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "id": "7rk42B4gZQp-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>thres_0.1</th>\n",
       "      <td>0.724333</td>\n",
       "      <td>0.724156</td>\n",
       "      <td>0.726402</td>\n",
       "      <td>0.727557</td>\n",
       "      <td>0.724350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.15</th>\n",
       "      <td>0.735332</td>\n",
       "      <td>0.735323</td>\n",
       "      <td>0.737600</td>\n",
       "      <td>0.738590</td>\n",
       "      <td>0.735454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.2</th>\n",
       "      <td>0.746393</td>\n",
       "      <td>0.745858</td>\n",
       "      <td>0.747961</td>\n",
       "      <td>0.748624</td>\n",
       "      <td>0.746095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.25</th>\n",
       "      <td>0.756926</td>\n",
       "      <td>0.755785</td>\n",
       "      <td>0.757597</td>\n",
       "      <td>0.758852</td>\n",
       "      <td>0.755995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.3</th>\n",
       "      <td>0.765784</td>\n",
       "      <td>0.764678</td>\n",
       "      <td>0.766417</td>\n",
       "      <td>0.767069</td>\n",
       "      <td>0.764617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.35</th>\n",
       "      <td>0.773051</td>\n",
       "      <td>0.771821</td>\n",
       "      <td>0.773734</td>\n",
       "      <td>0.774347</td>\n",
       "      <td>0.772436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.4</th>\n",
       "      <td>0.775933</td>\n",
       "      <td>0.775487</td>\n",
       "      <td>0.776853</td>\n",
       "      <td>0.777843</td>\n",
       "      <td>0.775808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.45</th>\n",
       "      <td>0.775242</td>\n",
       "      <td>0.775099</td>\n",
       "      <td>0.775334</td>\n",
       "      <td>0.776493</td>\n",
       "      <td>0.774595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.5</th>\n",
       "      <td>0.768023</td>\n",
       "      <td>0.767553</td>\n",
       "      <td>0.767252</td>\n",
       "      <td>0.768677</td>\n",
       "      <td>0.766623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.55</th>\n",
       "      <td>0.750433</td>\n",
       "      <td>0.750153</td>\n",
       "      <td>0.750391</td>\n",
       "      <td>0.752209</td>\n",
       "      <td>0.749522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.6</th>\n",
       "      <td>0.719877</td>\n",
       "      <td>0.719969</td>\n",
       "      <td>0.720218</td>\n",
       "      <td>0.723170</td>\n",
       "      <td>0.720690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.65</th>\n",
       "      <td>0.674725</td>\n",
       "      <td>0.676120</td>\n",
       "      <td>0.673587</td>\n",
       "      <td>0.678092</td>\n",
       "      <td>0.675105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.7</th>\n",
       "      <td>0.610035</td>\n",
       "      <td>0.613854</td>\n",
       "      <td>0.609716</td>\n",
       "      <td>0.617069</td>\n",
       "      <td>0.611858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.75</th>\n",
       "      <td>0.528897</td>\n",
       "      <td>0.535377</td>\n",
       "      <td>0.529805</td>\n",
       "      <td>0.538821</td>\n",
       "      <td>0.531244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.8</th>\n",
       "      <td>0.437944</td>\n",
       "      <td>0.445869</td>\n",
       "      <td>0.438979</td>\n",
       "      <td>0.448749</td>\n",
       "      <td>0.440717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thres_0.85</th>\n",
       "      <td>0.338970</td>\n",
       "      <td>0.345781</td>\n",
       "      <td>0.340993</td>\n",
       "      <td>0.351517</td>\n",
       "      <td>0.340330</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0         1         2         3         4\n",
       "thres_0.1   0.724333  0.724156  0.726402  0.727557  0.724350\n",
       "thres_0.15  0.735332  0.735323  0.737600  0.738590  0.735454\n",
       "thres_0.2   0.746393  0.745858  0.747961  0.748624  0.746095\n",
       "thres_0.25  0.756926  0.755785  0.757597  0.758852  0.755995\n",
       "thres_0.3   0.765784  0.764678  0.766417  0.767069  0.764617\n",
       "thres_0.35  0.773051  0.771821  0.773734  0.774347  0.772436\n",
       "thres_0.4   0.775933  0.775487  0.776853  0.777843  0.775808\n",
       "thres_0.45  0.775242  0.775099  0.775334  0.776493  0.774595\n",
       "thres_0.5   0.768023  0.767553  0.767252  0.768677  0.766623\n",
       "thres_0.55  0.750433  0.750153  0.750391  0.752209  0.749522\n",
       "thres_0.6   0.719877  0.719969  0.720218  0.723170  0.720690\n",
       "thres_0.65  0.674725  0.676120  0.673587  0.678092  0.675105\n",
       "thres_0.7   0.610035  0.613854  0.609716  0.617069  0.611858\n",
       "thres_0.75  0.528897  0.535377  0.529805  0.538821  0.531244\n",
       "thres_0.8   0.437944  0.445869  0.438979  0.448749  0.440717\n",
       "thres_0.85  0.338970  0.345781  0.340993  0.351517  0.340330"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_thres = pd.DataFrame(scores_by_thres_, columns=[f\"thres_{str(i/100)}\"for i in range(10, 90, 5)])    # threshold : 0.1 ~ 0.85 \n",
    "f1_thres = f1_thres.T\n",
    "f1_thres\n",
    "# f1_thres = pd.DataFrame(scores_by_thres_, columns=[f\"thres_{str(i/100)}\"for i in range(10, 90, 5)])    # threshold : 0.1 ~ 0.85 \n",
    "# f1_thres = f1_thres.T\n",
    "# # f1_thres\n",
    "# f1_thres.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "id": "v1vTzxvGZw-C"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    thres_0.4\n",
       "1    thres_0.4\n",
       "2    thres_0.4\n",
       "3    thres_0.4\n",
       "4    thres_0.4\n",
       "dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_thres.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_by_thres_ = [] \n",
    "\n",
    "for i,(tri, vai) in enumerate( cv.split(x_train)):\n",
    "    # -----------------------------------------------------------\n",
    "    # * Assign train/valid set -> CatBoost.FeatureData()\n",
    "    x_tra = x_train.iloc[tri].copy() \n",
    "    train_labels = y_train[tri].copy() \n",
    "    x_val = x_train.iloc[vai].copy() \n",
    "    valid_labels = y_train[vai].copy() \n",
    "    \n",
    "    train_data = Pool(\n",
    "        data=FeaturesData(\n",
    "            num_feature_data=x_tra[ordinal_feats].astype(np.float32).values,\n",
    "            # num_feature_data=x_tra[ordinal_feats].values,\n",
    "            # cat_feature_data=x_tra[cat_features].astype('object').values,    # [342, 0, ...], dtype=object <- 에러남\n",
    "            cat_feature_data=x_tra[cat_features].astype(str).values,    # ['342', '0', ...], dtype=object <- 속도 많이 걸림 \n",
    "            # cat_feature_data=x_tra[cat_features].values,\n",
    "            num_feature_names=ordinal_feats, \n",
    "            cat_feature_names=cat_features\n",
    "            ),\n",
    "        label=train_labels\n",
    "    )\n",
    "    \n",
    "    valid_data = Pool(\n",
    "        data=FeaturesData(\n",
    "            num_feature_data=x_val[ordinal_feats].astype(np.float32).values,\n",
    "            # num_feature_data=x_val[ordinal_feats].values,\n",
    "            # cat_feature_data=x_val[cat_features].astype('object').values,\n",
    "            cat_feature_data=x_val[cat_features].astype(str).values,\n",
    "            # cat_feature_data=x_val[cat_features].values,\n",
    "            num_feature_names=ordinal_feats, \n",
    "            cat_feature_names=cat_features\n",
    "            ),\n",
    "        label=valid_labels\n",
    "    )\n",
    "    # -----------------------------------------------------------\n",
    "    pred_proba = models[i].predict_proba(valid_data)[:, 1]\n",
    "\n",
    "    sco_by_thres_ = []\n",
    "    for thrs_ in range(300, 400, 5):    # threshold : 0.3 ~ 0.395 \n",
    "\n",
    "        threshold = thrs_/1000\n",
    "        pred = np.where(pred_proba >= threshold , 1, 0)\n",
    "        score = f1_score(y_train[vai],pred)\n",
    "\n",
    "        sco_by_thres_.append(score)\n",
    "    \n",
    "    scores_by_thres_.append(sco_by_thres_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scores_by_thres_ = [] \n",
    "\n",
    "# for i,(tri, vai) in enumerate( cv.split(x_train)):\n",
    "#     pred_proba = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "\n",
    "#     sco_by_thres_ = []\n",
    "#     for thrs_ in range(300, 400, 5):    # threshold : 0.3 ~ 0.395 \n",
    "\n",
    "#         threshold = thrs_/1000\n",
    "#         pred = np.where(pred_proba >= threshold , 1, 0)\n",
    "#         score = f1_score(y_train[vai],pred)\n",
    "\n",
    "#         sco_by_thres_.append(score)\n",
    "    \n",
    "#     scores_by_thres_.append(sco_by_thres_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    thres_0.395\n",
       "1     thres_0.39\n",
       "2    thres_0.395\n",
       "3    thres_0.395\n",
       "4    thres_0.395\n",
       "dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_thres = pd.DataFrame(scores_by_thres_, columns=[f\"thres_{str(i/1000)}\"for i in range(300, 400, 5)])    # threshold : 0.1 ~ 0.85 \n",
    "f1_thres = f1_thres.T\n",
    "# f1_thres\n",
    "f1_thres.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_thres.idxmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "ofbZ9L6mxzcU"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.395, 0.39, 0.395, 0.395, 0.395]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "thresholds_list = [float(idx_.split('_')[-1]) for idx_ in f1_thres.idxmax()]\n",
    "thresholds_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8V5W022B77ui"
   },
   "source": [
    "## adjusting threshold "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "AP1en3aq77ui"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.394"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# threshold = 0.4\n",
    "\n",
    "# thresholds_list = [float(idx_.split('_')[-1]) for idx_ in f1_thres.idxmax()]\n",
    "np.mean(thresholds_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-PETOfwP77uj"
   },
   "source": [
    "# Check result of adjusting threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * scores_F1 of Validation set : [0.7757541183677096, 0.775375523729185, 0.7766848611559347, 0.7777710385241656, 0.7757345900728168]\n",
      " * The Avg. of F1 scores : 0.7762640263699623\n"
     ]
    }
   ],
   "source": [
    "pred_list = []\n",
    "scores = []\n",
    "\n",
    "thresholds_list = [float(idx_.split('_')[-1]) for idx_ in f1_thres.idxmax()]\n",
    "# >>> [0.37, 0.36, 0.36, 0.35, 0.37]\n",
    "\n",
    "test_data = Pool(\n",
    "    data=FeaturesData(\n",
    "        num_feature_data=x_test[ordinal_feats].astype(np.float32).values,\n",
    "        cat_feature_data=x_test[cat_features].astype(str).values,\n",
    "        num_feature_names=ordinal_feats, \n",
    "        cat_feature_names=cat_features\n",
    "        )\n",
    ")\n",
    "\n",
    "\n",
    "# for i,(tri, vai) in enumerate( cv.split(x_train) ):\n",
    "for i, (thres_, (tri, vai)) in enumerate(zip(thresholds_list, cv.split(x_train))):\n",
    "    # -----------------------------------------------------------\n",
    "    # * Assign train/valid set -> CatBoost.FeatureData()\n",
    "    x_tra = x_train.iloc[tri].copy() \n",
    "    train_labels = y_train[tri].copy() \n",
    "    x_val = x_train.iloc[vai].copy() \n",
    "    valid_labels = y_train[vai].copy() \n",
    "    \n",
    "    train_data = Pool(\n",
    "        data=FeaturesData(\n",
    "            num_feature_data=x_tra[ordinal_feats].astype(np.float32).values,\n",
    "            # num_feature_data=x_tra[ordinal_feats].values,\n",
    "            # cat_feature_data=x_tra[cat_features].astype('object').values,    # [342, 0, ...], dtype=object <- 에러남\n",
    "            cat_feature_data=x_tra[cat_features].astype(str).values,    # ['342', '0', ...], dtype=object <- 속도 많이 걸림 \n",
    "            # cat_feature_data=x_tra[cat_features].values,\n",
    "            num_feature_names=ordinal_feats, \n",
    "            cat_feature_names=cat_features\n",
    "            ),\n",
    "        label=train_labels\n",
    "    )\n",
    "    \n",
    "    valid_data = Pool(\n",
    "        data=FeaturesData(\n",
    "            num_feature_data=x_val[ordinal_feats].astype(np.float32).values,\n",
    "            # num_feature_data=x_val[ordinal_feats].values,\n",
    "            # cat_feature_data=x_val[cat_features].astype('object').values,\n",
    "            cat_feature_data=x_val[cat_features].astype(str).values,\n",
    "            # cat_feature_data=x_val[cat_features].values,\n",
    "            num_feature_names=ordinal_feats, \n",
    "            cat_feature_names=cat_features\n",
    "            ),\n",
    "        label=valid_labels\n",
    "    )\n",
    "    # -----------------------------------------------------------\n",
    "    pred_proba = models[i].predict_proba(valid_data)[:, 1]\n",
    "    # pred = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "    # pred = np.where(pred >= threshold , 1, 0)\n",
    "    pred = np.where(pred_proba >= thres_ , 1, 0)\n",
    "    score = f1_score(y_train[vai],pred)\n",
    "    scores.append(score)\n",
    "    pred = models[i].predict_proba(test_data)[:, 1]\n",
    "    pred_list.append(pred)\n",
    "\n",
    "print(f\" * scores_F1 of Validation set : {scores}\")\n",
    "print(f\" * The Avg. of F1 scores : {np.mean(scores)}\")\n",
    "\n",
    "#  * scores_F1 of Validation set : [0.7192216943016904, 0.7181671176291647, 0.7174627080896608, 0.7179099969797644, 0.7157041836146495]\n",
    "#  * The Avg. of F1 scores : 0.717693140122986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 84091,
     "status": "ok",
     "timestamp": 1641195827362,
     "user": {
      "displayName": "Seo in Seoul",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Ghwk1keCboZ5G83G8PzmpDMAtCmb94WL-59SAiJ=s64",
      "userId": "18324634975507226440"
     },
     "user_tz": -540
    },
    "id": "Cm7hNXYf77uj",
    "outputId": "aac2d0a1-1d34-43a7-9bfb-7a4d08d8ea6b"
   },
   "outputs": [],
   "source": [
    "# pred_list = []\n",
    "# scores = []\n",
    "\n",
    "# thresholds_list = [float(idx_.split('_')[-1]) for idx_ in f1_thres.idxmax()]\n",
    "# # >>> [0.37, 0.36, 0.36, 0.35, 0.37]\n",
    "\n",
    "# for i, (thres_, (tri, vai)) in enumerate(zip(thresholds_list, cv.split(x_train))):\n",
    "\n",
    "#     pred_proba = models[i].predict_proba(x_train.iloc[vai])[:, 1]\n",
    "#     pred = np.where(pred_proba >= thres_ , 1, 0)\n",
    "#     score = f1_score(y_train[vai],pred)\n",
    "#     scores.append(score)\n",
    "#     pred = models[i].predict_proba(x_test)[:, 1] \n",
    "#     pred_list.append(pred)\n",
    "\n",
    "# print(f\" * scores_F1 of Validation set : {scores}\")\n",
    "# print(f\" * The Avg. of F1 scores : {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* best Threshold : 0.394\n"
     ]
    }
   ],
   "source": [
    "# Model 8_component1. \n",
    "pred_proba = np.mean(pred_list , axis = 0 )\n",
    "pred = np.where(pred_proba >= np.mean(thresholds_list),1 ,0)\n",
    "print(f\"* best Threshold : {np.mean(thresholds_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    46404.000000\n",
       "mean         0.633534\n",
       "std          0.047330\n",
       "min          0.423795\n",
       "25%          0.604547\n",
       "50%          0.644055\n",
       "75%          0.668520\n",
       "max          0.753534\n",
       "dtype: float64"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(pred_proba).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(SUBMIT_PATH+f'sample_submission.csv')\n",
    "\n",
    "sample_submission['target'] = pred_proba\n",
    "sample_submission.to_csv(SUBMIT_PATH+f'imblearn_proba.csv', index=False)\n",
    "pred_proba_m8_c1 = pred_proba.copy()\n",
    "\n",
    "sample_submission['target'] = pred\n",
    "sample_submission.to_csv(SUBMIT_PATH+f'imblearn_pred.csv', index=False)\n",
    "pred_m8_c1 = pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    46404\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results \n",
    "sample_submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Fixed Threshold : 0.5\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.5 \n",
    "fixed_thres = 0.5\n",
    "\n",
    "pred_proba = np.mean(pred_list, axis = 0 )\n",
    "pred = np.where(pred_proba >= fixed_thres, 1, 0)\n",
    "print(f\" * Fixed Threshold : {fixed_thres}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(SUBMIT_PATH+f'sample_submission.csv')\n",
    "\n",
    "sample_submission['target'] = pred_proba\n",
    "sample_submission.to_csv(SUBMIT_PATH+f'imblearn_proba_th05.csv', index=False)\n",
    "pred_proba_m8_c1 = pred_proba.copy()\n",
    "\n",
    "sample_submission['target'] = pred\n",
    "sample_submission.to_csv(SUBMIT_PATH+f'imblearn_pred_th05.csv', index=False)\n",
    "pred_m8_c1 = pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    46042\n",
       "0      362\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results \n",
    "sample_submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Fixed Threshold : 0.6\n"
     ]
    }
   ],
   "source": [
    "# Threshold = 0.6 \n",
    "fixed_thres = 0.6\n",
    "\n",
    "pred_proba = np.mean(pred_list, axis = 0 )\n",
    "pred = np.where(pred_proba >= fixed_thres, 1, 0)\n",
    "print(f\" * Fixed Threshold : {fixed_thres}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission = pd.read_csv(SUBMIT_PATH+f'sample_submission.csv')\n",
    "\n",
    "sample_submission['target'] = pred_proba\n",
    "sample_submission.to_csv(SUBMIT_PATH+f'imblearn_proba_th06.csv', index=False)\n",
    "pred_proba_m8_c1 = pred_proba.copy()\n",
    "\n",
    "sample_submission['target'] = pred\n",
    "sample_submission.to_csv(SUBMIT_PATH+f'imblearn_pred_th06.csv', index=False)\n",
    "pred_m8_c1 = pred.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    35795\n",
       "0    10609\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results \n",
    "sample_submission['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    464475\n",
       "0.0    388913\n",
       "dtype: int64"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# imbalanced ratio\n",
    "pd.Series(y_train).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "[BaseModel]catboost+CV5Fold_threshold4e-1_Model03_1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
